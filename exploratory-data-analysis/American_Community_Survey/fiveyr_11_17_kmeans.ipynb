{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"\n",
    "STEP 0 >> imports; def clean_census & other functions\n",
    "\"\"\"\n",
    "\n",
    "# default cleaning method until proven otherwise\n",
    "def clean_census_frame(csv_path , head=False , reset=True , set_index=False ):\n",
    "    '''\n",
    "    inputs) \n",
    "        >> csv_path\n",
    "            > path to csv\n",
    "        >> head\n",
    "            > default=False\n",
    "                >> if != False\n",
    "                    > integer\n",
    "                        >> returns the first {head} rows (using .head() method) \n",
    "                            > instead of enitre dataframe\n",
    "        >> reset\n",
    "            > default=True\n",
    "                >> resets index after taking out rows\n",
    "            > if set to False\n",
    "                >> will not reset index\n",
    "        >> set_index\n",
    "            > default=False\n",
    "            > if != False\n",
    "                >> will set_index of new df to set_index\n",
    "    output)\n",
    "        >> dataframe cleaned like 2000 Census age&sex by 5-digit Zip Code (also how 2010 for same is cleaned)\n",
    "    how)\n",
    "        1. reads in csv , assumes it's large\n",
    "        2. makes a copy for editing \n",
    "            > and potential future use\n",
    "        3. locates readable column names  and non-readable names \n",
    "            > readable\n",
    "                    > e.g. Estimate; SEX AND AGE - Total population\n",
    "                >> assumes they are currently in row 0\n",
    "            > non-readable\n",
    "                    > e.g. HC01_VC03\n",
    "                >> assumes they are currently == dataframe.columns\n",
    "        4. replaces dataframe.columns (non-readable) with readable column names\n",
    "            > and drops the old 0th column (column where readable names were stored)\n",
    "        \n",
    "    '''\n",
    "    # load data\n",
    "    df = pd.read_csv( csv_path , low_memory=False )\n",
    "\n",
    "    # and copy\n",
    "    _df = df.copy()\n",
    "\n",
    "    # reset column names to current 0th row values\n",
    "    _df.columns = _df.iloc[0]\n",
    "    # new 2000 dataframe without row where values are from\n",
    "    clean_df = _df[1:]\n",
    "    \n",
    "    # default\n",
    "    if reset==True:\n",
    "        # reset index\n",
    "        clean_df = clean_df.reset_index()\n",
    "        \n",
    "    # set_index\n",
    "    if set_index:\n",
    "        clean_df = clean_df.set_index(set_index)\n",
    "    \n",
    "    if head:\n",
    "        # return first {head} rows of dataframe\n",
    "        return clean_df.head(head)\n",
    "    else:\n",
    "        # return dataframe\n",
    "        return clean_df\n",
    "\n",
    "'''\n",
    "STEP 1 >> load data, reset; make copies\n",
    "'''\n",
    "def load_copy_data(i):\n",
    "    '''\n",
    "    loads data\n",
    "    \n",
    "    input)\n",
    "        >> i\n",
    "            > if 0\n",
    "                >> .reset_index() after deleting row contining column names\n",
    "            > if 1\n",
    "                >> do not .reset_index()\n",
    "                \n",
    "    '''\n",
    "    if i==0:\n",
    "        # load with reset\n",
    "        # 2011 \n",
    "        twenty_eleven = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_11_5YR_DP05_with_ann.csv')\n",
    "        # 2012\n",
    "        # twenty_twelve = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_12_5YR_DP05_with_ann.csv')\n",
    "        #2013\n",
    "        # twenty_thirteen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_13_5YR_DP05_with_ann.csv')\n",
    "        # 2014\n",
    "        # twenty_fourteen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_14_5YR_DP05_with_ann.csv')\n",
    "        # 2015\n",
    "        # twenty_fifteen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_15_5YR_DP05_with_ann.csv')\n",
    "        #2016\n",
    "        # twenty_sixteen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_16_5YR_DP05_with_ann.csv')\n",
    "        #2017\n",
    "        # twenty_seventeen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_17_5YR_DP05_with_ann.csv')\n",
    "    if i==1:\n",
    "        # load without reset\n",
    "        # 2011 \n",
    "        twenty_eleven = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_11_5YR_DP05_with_ann.csv',reset=False)\n",
    "        # 2012\n",
    "        # twenty_twelve = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_12_5YR_DP05_with_ann.csv',reset=False)\n",
    "        #2013\n",
    "        # twenty_thirteen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_13_5YR_DP05_with_ann.csv',reset=False)\n",
    "        # 2014\n",
    "        # twenty_fourteen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_14_5YR_DP05_with_ann.csv',reset=False)\n",
    "        # 2015\n",
    "        # twenty_fifteen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_15_5YR_DP05_with_ann.csv',reset=False)\n",
    "        #2016\n",
    "        # twenty_sixteen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_16_5YR_DP05_with_ann.csv',reset=False)\n",
    "        #2017\n",
    "        # twenty_seventeen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_17_5YR_DP05_with_ann.csv',reset=False)\n",
    "    \n",
    "    # copy \n",
    "    # 2011 \n",
    "    _y2k11 = twenty_eleven.copy()\n",
    "    # 2012\n",
    "    # _y2k12 = twenty_twelve.copy()\n",
    "    #2013\n",
    "    # _y2k13 = twenty_thirteen.copy()\n",
    "    # 2014\n",
    "    # _y2k14 = twenty_fourteen.copy()\n",
    "    # 2015\n",
    "    # _y2k15 = twenty_fifteen.copy()\n",
    "    #2016\n",
    "    # _y2k16 = twenty_sixteen.copy()\n",
    "    #2017\n",
    "    # _y2k17 = twenty_seventeen.copy()\n",
    "    \n",
    "    # output list of copied frames\n",
    "    return _y2k11  # [_y2k11,_y2k12,_y2k13,_y2k14,_y2k15,_y2k16,_y2k17]\n",
    "\n",
    "\n",
    "def test_non_unique(column_names):\n",
    "    '''\n",
    "    input) \n",
    "        >> list of column names {column_names}\n",
    "            > columns to check for duplicate instances\n",
    "    output)\n",
    "        >> indexed list of names occouring more than once \n",
    "    '''\n",
    "    # store first instance\n",
    "    first_occour = []\n",
    "    # store 2nd+ instance(s)\n",
    "    non_unique = []\n",
    "    # we're going to want index\n",
    "    for i,_ in enumerate(column_names):\n",
    "        # not first time\n",
    "        if _ not in first_occour:\n",
    "            first_occour.append(_)\n",
    "        # if not first, tag&bag\n",
    "        else:\n",
    "            non_unique.append([i,_])\n",
    "    # output index w/ non-first instances\n",
    "    return non_unique\n",
    "\n",
    "\n",
    "def to_numeric_but(save_these_columns,dataframe):\n",
    "    '''\n",
    "    split into 2 df and rejoin after convert to int\n",
    "    \n",
    "    inputs:\n",
    "        >> save_these_columns=number of columns to save\n",
    "            > currently must include one end of df \n",
    "                >> might could run function multiple times to edit slices\n",
    "                >> single number, not range (yet)\n",
    "        >> dataframe\n",
    "            > dataframe to shif to numeric (but)\n",
    "    output:\n",
    "        >> concatted pd.DataFrame of \n",
    "            > og columns you chose to save\n",
    "            > columns converted to numeric\n",
    "    '''\n",
    "    # copy df for editing\n",
    "    k = dataframe.copy()\n",
    "\n",
    "    # columns to save\n",
    "    save_k = k[k.columns[:save_these_columns]]\n",
    "    # columns to edit\n",
    "    switch_k = k[k.columns[save_these_columns:]]\n",
    "\n",
    "    # edited columns  # coerce , ignore , raise\n",
    "    swapped_k = switch_k.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # new (edited) dataframe\n",
    "    new_k = pd.concat([save_k,swapped_k],axis=1)\n",
    "\n",
    "    return new_k\n",
    "\n",
    "\n",
    "def geography_to_zipcode_ids_to_numeric(dataframe):\n",
    "    '''\n",
    "    convert \n",
    "        >> .Geography values \n",
    "            > like 'ZCTA5 00601' \n",
    "            > to int(00601)\n",
    "        >> .Id values\n",
    "            > like '8600000US00601' \n",
    "            > to int(860000000601)\n",
    "        >> .Id2 values\n",
    "            > like '00601'\n",
    "            > to int(00601)\n",
    "    '''\n",
    "    # copy\n",
    "    df = dataframe.copy()\n",
    "    \n",
    "    # set old Geography\n",
    "    geo = df.Geography\n",
    "    # set old Id\n",
    "    _id = df.Id\n",
    "    # set old Id2\n",
    "    __id2 = df.Id2\n",
    "    \n",
    "    # make new 'Geography' values\n",
    "    new_geos = [int(i[-5:]) for i in geo]\n",
    "    # new 'Id' values\n",
    "    new_id = [int(''.join(i.split('US'))) for i in _id]\n",
    "    # new .Id2 instances\n",
    "    new__id2 = [int(d) for d in __id2]\n",
    "    \n",
    "    # convert dataframe\n",
    "    new_df = df.copy()\n",
    "    new_df.Geography = new_geos\n",
    "    new_df.Id = new_id\n",
    "    new_df.Id2 = new__id2\n",
    "    \n",
    "    # return new df\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def kmeans_by(dataframe,n_clusters):\n",
    "    '''\n",
    "    inputs:\n",
    "        >> dataframe\n",
    "            > dataframe to be edited\n",
    "        >> n_clusters\n",
    "            > number of clusters for KMeans\n",
    "    output:\n",
    "        > pd.Dataframe of \n",
    "    '''\n",
    "    # copy data \n",
    "    y2k11 = dataframe.copy()  \n",
    "\n",
    "    # convert all but first 3 columns to numeric\n",
    "    data = y2k11.copy()\n",
    "    k2011 = to_numeric_but(save_these_columns=3,dataframe=data)\n",
    "\n",
    "    # now convert the first 3 columns\n",
    "    adjust_first_3 = k2011.copy()\n",
    "    _2011df_ = geography_to_zipcode_ids_to_numeric(adjust_first_3)\n",
    "\n",
    "    '''KMeans'''\n",
    "    # fill NaN values\n",
    "    t = _2011df_.copy().fillna(0)\n",
    "    \n",
    "    # Convert DataFrame to matrix\n",
    "    mat = t.values\n",
    "    \n",
    "    # Using sklearn\n",
    "    km = KMeans(n_clusters)\n",
    "    # fit our values\n",
    "    km.fit(mat)\n",
    "    \n",
    "    # Get cluster assignment labels\n",
    "    labels = km.labels_\n",
    "    \n",
    "    # Format results as a DataFrame\n",
    "    results = pd.DataFrame([t.index,labels]).T\n",
    "\n",
    "    # display results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load w/o reset\n",
    "f = load_copy_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy for safeguard and hedge reload\n",
    "frames = f.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract copy of 2011 \n",
    "y2k11 = frames.copy()  #[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33120 entries, 1 to 33120\n",
      "Columns: 327 entries, Id to Percent Margin of Error; HISPANIC OR LATINO AND RACE - Total housing units\n",
      "dtypes: object(327)\n",
      "memory usage: 82.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# examine (2011)\n",
    "y2k11.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuy11 = test_non_unique(y2k11)\n",
    "len(nuy11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all but first 3 columns to numeric\n",
    "data = y2k11.copy()\n",
    "k2011 = to_numeric_but(save_these_columns=3,dataframe=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33120 entries, 1 to 33120\n",
      "Columns: 407 entries, Id to Percent Margin of Error; HISPANIC OR LATINO AND RACE - Total housing units\n",
      "dtypes: float64(235), int64(169), object(3)\n",
      "memory usage: 102.8+ MB\n"
     ]
    }
   ],
   "source": [
    "k2011.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonuni = test_non_unique(k2011)\n",
    "len(nonuni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[87, 'Estimate; SEX AND AGE - 18 years and over'],\n",
       "  [88, 'Margin of Error; SEX AND AGE - 18 years and over']],\n",
       " [[8, 'Estimate; SEX AND AGE - Male'], [9, 'Estimate; SEX AND AGE - Male']])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuy11[:2] , nonuni[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(k2011.columns[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in k2011.columns:\n",
    "    if i not in y2k11.columns:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now convert the first 3 columns\n",
    "adjust_first_3 = k2011.copy()\n",
    "_2011df_ = geography_to_zipcode_ids_to_numeric(adjust_first_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand_test = _2011df_.copy()\n",
    "# rand_test['Margin of Error; SEX AND AGE - Total population'].apply(lambda x : 0 if x =='*****' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33120 entries, 1 to 33120\n",
      "Columns: 407 entries, Id to Percent Margin of Error; HISPANIC OR LATINO AND RACE - Total housing units\n",
      "dtypes: float64(235), int64(172)\n",
      "memory usage: 102.8 MB\n"
     ]
    }
   ],
   "source": [
    "_2011df_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _2011df_ = _2011df_.dropna()  # , how='any'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33120 entries, 1 to 33120\n",
      "Columns: 407 entries, Id to Percent Margin of Error; HISPANIC OR LATINO AND RACE - Total housing units\n",
      "dtypes: float64(235), int64(172)\n",
      "memory usage: 102.8 MB\n"
     ]
    }
   ],
   "source": [
    "# no change\n",
    "_2011df_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _2011df_.head(15)\n",
    "# _2011df_ = _2011df_.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _2011df_['Margin of Error; SEX AND AGE - Total population'].apply(lambda x : 0 for x in i if x =='*****' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=-1\n",
    "x_out=set()\n",
    "star_out=set()\n",
    "other_out=set()\n",
    "for i in _2011df_.sample(100,axis=0).values:\n",
    "    x+=1\n",
    "    y=0\n",
    "    for j in i:\n",
    "        y+=1\n",
    "        if j == '(X)':\n",
    "            x_out.add((x-1,y))\n",
    "        if j == '*****':\n",
    "            star_out.add((x-1,y))\n",
    "        if j == '**':\n",
    "            star_out.add((x-1,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectj = []\n",
    "for i,j in x_out: \n",
    "    collectj.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "collecti = []\n",
    "for j,i in star_out: \n",
    "    collecti.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_out=[]\n",
    "for n in set(collectj):\n",
    "    q = collectj.count(n)\n",
    "    count_out.append((n,q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_in=[]\n",
    "for m in set(collecti):\n",
    "    p = collectj.count(m)\n",
    "    count_in.append((m,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [column, count]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = pd.DataFrame(data=count_out,columns=['column','count'])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [row, count]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = pd.DataFrame(data=count_in,columns=['row','count'])\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = _2011df_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [_2011df_.columns[q-1] for q,b in count_out]\n",
    "stars = [_2011df_.columns[q-1] for q,b in count_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols_to_drop), len(stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert '*****' to 0\n",
    "for i in stars: \n",
    "    # test.drop(stars,axis=1)\n",
    "    test[i].apply(lambda x : 0 if x == '*****' else x)\n",
    "# drop columns with '(X)'\n",
    "# for cols in \n",
    "test = test.drop(cols_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33120 entries, 1 to 33120\n",
      "Columns: 407 entries, Id to Percent Margin of Error; HISPANIC OR LATINO AND RACE - Total housing units\n",
      "dtypes: float64(235), int64(172)\n",
      "memory usage: 102.8 MB\n"
     ]
    }
   ],
   "source": [
    "test.info()  #['Percent Margin of Error; HISPANIC OR LATINO AND RACE - Total housing units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ivalues = [i for i in test.values]\n",
    "# # # [i for i in ivalues if i == '**']\n",
    "# # for i in range(len(test.values)):\n",
    "# #     if test.values[i].any() == '**':\n",
    "# #         print(i,test.values[i])\n",
    "# # sus=set()\n",
    "# # for i in test:\n",
    "# #     for x in test[i]:\n",
    "# #         if x == '**':\n",
    "# #             sus.add(i)\n",
    "\n",
    "# for i in test.columns:\n",
    "#     test[i].apply(lambda q: 0 if x == '**' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***notes***:\n",
    "    - that wasn't too hard\n",
    "- ***actions***:\n",
    "    - drop these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test.copy().fillna(0)\n",
    "# Convert DataFrame to matrix\n",
    "mat = t.values\n",
    "# Using sklearn\n",
    "km = KMeans(n_clusters=5)\n",
    "# fit our values\n",
    "km.fit(mat)\n",
    "# Get cluster assignment labels\n",
    "labels = km.labels_\n",
    "# Format results as a DataFrame\n",
    "results = pd.DataFrame([t.index,labels]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33090</th>\n",
       "      <td>33091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33091</th>\n",
       "      <td>33092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33092</th>\n",
       "      <td>33093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33093</th>\n",
       "      <td>33094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33094</th>\n",
       "      <td>33095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33095</th>\n",
       "      <td>33096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33096</th>\n",
       "      <td>33097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33097</th>\n",
       "      <td>33098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33098</th>\n",
       "      <td>33099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33099</th>\n",
       "      <td>33100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33100</th>\n",
       "      <td>33101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33101</th>\n",
       "      <td>33102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33102</th>\n",
       "      <td>33103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33103</th>\n",
       "      <td>33104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33104</th>\n",
       "      <td>33105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33105</th>\n",
       "      <td>33106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33106</th>\n",
       "      <td>33107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33107</th>\n",
       "      <td>33108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33108</th>\n",
       "      <td>33109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33109</th>\n",
       "      <td>33110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33110</th>\n",
       "      <td>33111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33111</th>\n",
       "      <td>33112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33112</th>\n",
       "      <td>33113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33113</th>\n",
       "      <td>33114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33114</th>\n",
       "      <td>33115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33115</th>\n",
       "      <td>33116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33116</th>\n",
       "      <td>33117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33117</th>\n",
       "      <td>33118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33118</th>\n",
       "      <td>33119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33119</th>\n",
       "      <td>33120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1\n",
       "0          1  2\n",
       "1          2  2\n",
       "2          3  3\n",
       "3          4  4\n",
       "4          5  2\n",
       "5          6  3\n",
       "6          7  4\n",
       "7          8  2\n",
       "8          9  4\n",
       "9         10  3\n",
       "10        11  2\n",
       "11        12  2\n",
       "12        13  4\n",
       "13        14  2\n",
       "14        15  2\n",
       "15        16  2\n",
       "16        17  2\n",
       "17        18  4\n",
       "18        19  2\n",
       "19        20  4\n",
       "20        21  4\n",
       "21        22  2\n",
       "22        23  2\n",
       "23        24  2\n",
       "24        25  2\n",
       "25        26  2\n",
       "26        27  2\n",
       "27        28  2\n",
       "28        29  4\n",
       "29        30  3\n",
       "...      ... ..\n",
       "33090  33091  0\n",
       "33091  33092  0\n",
       "33092  33093  0\n",
       "33093  33094  0\n",
       "33094  33095  0\n",
       "33095  33096  1\n",
       "33096  33097  0\n",
       "33097  33098  0\n",
       "33098  33099  0\n",
       "33099  33100  0\n",
       "33100  33101  0\n",
       "33101  33102  0\n",
       "33102  33103  0\n",
       "33103  33104  0\n",
       "33104  33105  0\n",
       "33105  33106  0\n",
       "33106  33107  0\n",
       "33107  33108  0\n",
       "33108  33109  0\n",
       "33109  33110  1\n",
       "33110  33111  0\n",
       "33111  33112  0\n",
       "33112  33113  0\n",
       "33113  33114  0\n",
       "33114  33115  0\n",
       "33115  33116  0\n",
       "33116  33117  0\n",
       "33117  33118  0\n",
       "33118  33119  0\n",
       "33119  33120  0\n",
       "\n",
       "[33120 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy df for editing\n",
    "k11 = y2k11.copy()\n",
    "\n",
    "'''split into 2 df and rejoin after convert to int'''\n",
    "# df to save\n",
    "save_k11 = k11.copy()\n",
    "# columns to save\n",
    "save_k11 = save_k11.copy()[save_k11.columns[:3]]\n",
    "\n",
    "# df to edit\n",
    "switch_k11 = k11.copy()\n",
    "# columns to edit\n",
    "switch_k11 = switch_k11.copy()[switch_k11.columns[3:]]\n",
    "\n",
    "# edited columns\n",
    "swapped_k11 = switch_k11.copy().apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# new (edited) dataframe\n",
    "new_k11 = pd.concat([save_k11,swapped_k11],axis=1)\n",
    "\n",
    "len(new_k11.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pull column names\n",
    "# k11_cols = y2k11.copy().columns[4:]\n",
    "# for c in range(len(k11_cols)):\n",
    "#     a = pd.Series(k11[k11_cols])\n",
    "# #     k11.loc[[k11_cols][c]] = pd.to_numeric(a,errors='ignore')\n",
    "# # pd.Series(k11[k11_cols[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k11_cols = y2k11.copy().columns\n",
    "__k11_cols__ = y2k11.copy().columns[4:]\n",
    "# len(k11_cols),len(__k11_cols__)\n",
    "print(f'{__k11_cols__[:3]}\\n{k11_cols[:3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in frames:\n",
    "    print(frame.info(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copies = frames[:2].copy()\n",
    "for df in copies:\n",
    "    for column in df.columns: \n",
    "        df[column] = pd.to_numeric([df[column]], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***NOTE***:\n",
    "    - path to mvp\n",
    "        - whiteboard_pics/acs_5yr_11-17_path-to-mvp.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_array = frames[0].values\n",
    "dataset_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 2 >> find all columns which coexist across all dataframes at current position\n",
    "'''\n",
    "columns_by_frame = [frame.columns for frame in frames]\n",
    "count_columns_by_frame = [len(frame) for frame in columns_by_frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "# for range of df with most columns\n",
    "for count in range(len(max(count_columns_by_frame))):\n",
    "    # if index of every frame is same as index of frame with most columns\n",
    "    if [frame for frame in columns_by_frame][count] == frames[6][count]:\n",
    "        out.append(count)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all\n",
    "years = frames  # [y2k11,y2k12,y2k13,y2k14,y2k15,y2k16,y2k17]\n",
    "for year in years:\n",
    "    print(len(year.columns),'\\n',year.info(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = np.array([[1, 2], [1, 4], [1, 0], [10, 2], [10, 4], [10, 0]])\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "kmeans.labels_\n",
    "\n",
    "# array([1, 1, 1, 0, 0, 0], dtype=int32)\n",
    "kmeans.predict([[0, 0], [12, 3]])\n",
    "# array([1, 0], dtype=int32)\n",
    "kmeans.cluster_centers_\n",
    "# array([[10.,  2.], [ 1.,  2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Scikit learn plays really well with Pandas, so I suggest you use it. Here's an example:\n",
    "\n",
    "# In [1]: \n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "data = np.reshape(np.random.randn(20),(10,2)) # 10 training examples\n",
    "labels = np.random.randint(2, size=10) # 10 labels\n",
    "\n",
    "# In [2]: \n",
    "X = pd.DataFrame(data)\n",
    "y = pd.Series(labels)\n",
    "\n",
    "# In [3]:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    random_state=0)\n",
    "\n",
    "# In [4]: X_test\n",
    "# Out[4]:\n",
    "\n",
    "#      0       1\n",
    "# 2   -1.39   -1.86\n",
    "# 8    0.48   -0.81\n",
    "# 4   -0.10   -1.83\n",
    "\n",
    "# In [5]: y_test\n",
    "# Out[5]:\n",
    "\n",
    "# 2    1\n",
    "# 8    1\n",
    "# 4    1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q=pd.read_csv('../../data/American_Community_Survey/aff_download/ACS_11_5YR_DP05_with_ann.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pizfsdazapizzaadsf = (2,1,0,4,32,7,2,9,5)\n",
    "max(pizfsdazapizzaadsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[3,2,1,4,6,5]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
