{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_census_frame(file_path):\n",
    "    '''\n",
    "    input) file_path\n",
    "        >> path to csv\n",
    "    '''\n",
    "    # load data\n",
    "    df = pd.read_csv( file_path , low_memory=False )\n",
    "\n",
    "    # and copy\n",
    "    _df = df.copy()\n",
    "\n",
    "    # reset column names to current 0th row values\n",
    "    _df.columns = _df.iloc[0]\n",
    "    # new 2000 dataframe without row where values are from\n",
    "    _df = _df[1:]\n",
    "    # reset index\n",
    "    clean_df = _df.reset_index()\n",
    "    \n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2011\n",
    "y2k11 = clean_census_frame('../data/acs/aff_download/ACS_11_5YR_DP05_with_ann.csv')\n",
    "# 2012\n",
    "y2k12 = clean_census_frame('../data/acs/aff_download/ACS_12_5YR_DP05_with_ann.csv')\n",
    "#2013\n",
    "y2k13 = clean_census_frame('../data/acs/aff_download/ACS_13_5YR_DP05_with_ann.csv')\n",
    "# 2014\n",
    "y2k14 = clean_census_frame('../data/acs/aff_download/ACS_14_5YR_DP05_with_ann.csv')\n",
    "# 2015\n",
    "y2k15 = clean_census_frame('../data/acs/aff_download/ACS_15_5YR_DP05_with_ann.csv')\n",
    "# 2016\n",
    "y2k16 = clean_census_frame('../data/acs/aff_download/ACS_16_5YR_DP05_with_ann.csv')\n",
    "# 2017\n",
    "y2k17 = clean_census_frame('../data/acs/aff_download/ACS_17_5YR_DP05_with_ann.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Geography'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather column names\n",
    "column_names = [_ for _ in y2k11[:0]]\n",
    "column_names[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33120 entries, 0 to 33119\n",
      "Columns: 328 entries, index to Percent Margin of Error; HISPANIC OR LATINO AND RACE - Total housing units\n",
      "dtypes: int64(1), object(327)\n",
      "memory usage: 82.9+ MB\n",
      "None \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33120 entries, 0 to 33119\n",
      "Columns: 328 entries, index to Percent Margin of Error; HISPANIC OR LATINO AND RACE - Total housing units\n",
      "dtypes: int64(1), object(327)\n",
      "memory usage: 82.9+ MB\n",
      "None \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33120 entries, 0 to 33119\n",
      "Columns: 328 entries, index to Percent Margin of Error; HISPANIC OR LATINO AND RACE - Total housing units\n",
      "dtypes: int64(1), object(327)\n",
      "memory usage: 82.9+ MB\n",
      "None \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33120 entries, 0 to 33119\n",
      "Columns: 328 entries, index to Percent Margin of Error; HISPANIC OR LATINO AND RACE - Total housing units\n",
      "dtypes: int64(1), object(327)\n",
      "memory usage: 82.9+ MB\n",
      "None \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33120 entries, 0 to 33119\n",
      "Columns: 340 entries, index to Percent Margin of Error; CITIZEN, VOTING AGE POPULATION - Citizen, 18 and over population - Female\n",
      "dtypes: int64(1), object(339)\n",
      "memory usage: 85.9+ MB\n",
      "None \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33120 entries, 0 to 33119\n",
      "Columns: 340 entries, index to Percent Margin of Error; CITIZEN, VOTING AGE POPULATION - Citizen, 18 and over population - Female\n",
      "dtypes: int64(1), object(339)\n",
      "memory usage: 85.9+ MB\n",
      "None \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33120 entries, 0 to 33119\n",
      "Columns: 360 entries, index to Percent Margin of Error; CITIZEN, VOTING AGE POPULATION - Citizen, 18 and over population - Female\n",
      "dtypes: int64(1), object(359)\n",
      "memory usage: 91.0+ MB\n",
      "None \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in [y2k11,y2k12,y2k13,y2k14,y2k15,y2k16,y2k17]:\n",
    "    print(_.info(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe for each zip code, should contain row from each year\n",
    "def frame_per_zip(dataframes):\n",
    "    '''\n",
    "    take dataframe for each year set is available\n",
    "    find common zipcode for each year\n",
    "    make dataframe for that zipcode\n",
    "        containing each year's measurements\n",
    "    note:\n",
    "        dataframes must be same length\n",
    "    '''\n",
    "    # check length of dataframes is same\n",
    "    for _ in range(len(dataframes)):\n",
    "        # done to ensure each zip code has same represnetation \n",
    "        if len(dataframes[_-1]) != len(dataframes[_]):\n",
    "            # stop if we have different lengths\n",
    "            raise Exception(f'len(dataframe[{-_}]) != len(dataframe[{_}])')\n",
    "        # also check that dataframes have same Id\n",
    "        random_samples = [random.randint(1,int(len(dataframes[-_])/2)),\n",
    "                          random.randint(1,int(len(dataframes[-_]))),\n",
    "                          random.randint(int(len(dataframes[-_])/2),len(dataframes[-_]))]\n",
    "        for sample in random_samples:\n",
    "            # pull Id from df to compare\n",
    "            if dataframes[_]['Id'][sample] != dataframes[_-2]['Id'][sample]:\n",
    "                # stop if they don't match\n",
    "                raise Exception(f\"NON MATCHING Id\\n{dataframes[_].Id[sample]}\\nERROR\\n{dataframes[_-2].Id[sample]}\\n\")\n",
    "    \n",
    "    # now we can get to work\n",
    "    mini_dfs = []\n",
    "    for i in range(len(dataframes[0])):\n",
    "        mini_df = pd.DataFrame(index=['2011','2012','2013','2014','2015','2016','2017'], columns=dataframes[0].columns)\n",
    "        for _ in range(len(dataframes)):\n",
    "            mini_df.iloc[_] = dataframes[_][i]\n",
    "        mini_dfs.append(mini_df)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    NaN\n",
       "b    NaN\n",
       "c    NaN\n",
       "d    NaN\n",
       "e    NaN\n",
       "Name: 2012, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_per_zip([y2k11,y2k12,y2k13,y2k14,y2k15,y2k16,y2k17])\n",
    "# mini_df = pd.DataFrame(index=['2011','2012','2013','2014','2015','2016','2017'], columns=['a','b','c','d','e'])\n",
    "# mini_df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes = [y2k11,y2k12,y2k13,y2k14,y2k15,y2k16,y2k17]\n",
    "# mini_df = pd.DataFrame(index=['2011','2012','2013','2014','2015','2016','2017'], columns=dataframes[0].columns)\n",
    "# mini_df.iloc[0] = 'lol'\n",
    "# mini_df.iloc[0]\n",
    "# mini_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# load 2000 data\n",
    "y2k = pd.read_csv( a , low_memory=False )\n",
    "# load 2010 data\n",
    "y2k10 = pd.read_csv( b , low_memory=False )\n",
    "\n",
    "# 2000 Census\n",
    "b = y2k.copy()\n",
    "# 2010 Census\n",
    "o = y2k10.copy()\n",
    "\n",
    "# reset 2000 columns to current 0th row values\n",
    "b.columns = b.iloc[0]\n",
    "# new 2000 dataframe without row where values are from\n",
    "b = b[1:]\n",
    "# reset index\n",
    "b = b.reset_index()\n",
    "\n",
    "# reset 2010 columns to current 0th row values\n",
    "o.columns = o.iloc[0]\n",
    "# new 2010 dataframe without row where values are from\n",
    "o = o[1:]\n",
    "# reset index\n",
    "o = o.reset_index()\n",
    "\n",
    "# identify zip codes from 2000 .Geography (last 5 chars of string)\n",
    "zip_2000_codes = [q[-5:] for q in b.Geography]  # ValueError: invalid literal for int() with base 10: '006HH'\n",
    "# identify zip codes from 2010 .Geography (last 5 chars of string)\n",
    "zip_2010_codes = [q[-5:] for q in o.Geography]\n",
    "\n",
    "# from 2000.Geography , instance is not seen in 2010.Geography  -- sample: zip_code = (2, 'c')\n",
    "in_2000_but_not_2010_from_2000 = [zip_code for zip_code in enumerate(zip_2000_codes) if zip_code[1] not in zip_2010_codes]\n",
    "# from 2010.Geography , instance is not seen in 2000.Geography  -- sample: zip_code[1] = 'c'\n",
    "in_2010_but_not_2000_from_2010 = [zip_code for zip_code in enumerate(zip_2010_codes) if zip_code[1] not in zip_2000_codes]\n",
    "\n",
    "# from 2000.Geography , instance is seen in 2010.Geography\n",
    "in_2000_and_2010_from_2000 = [zip_code for zip_code in enumerate(zip_2000_codes) if zip_code[1] in zip_2010_codes]\n",
    "# from 2010.Geography , instance is seen in 2000.Geography\n",
    "in_2010_and_2000_from_2010 = [zip_code for zip_code in enumerate(zip_2010_codes) if zip_code[1] in zip_2000_codes]\n",
    "\n",
    "# index of objects coexisting in 2000 and 2010\n",
    "of_2000_indexes = [i for i,j in in_2000_and_2010_from_2000]\n",
    "# index of objects coexisting in 2010 and 2000 \n",
    "of_2010_indexes = [i for i,j in in_2010_and_2000_from_2010]\n",
    "# ^note: these are different lists, if took j instead of i, then would be same list\n",
    "if [j for i,j in in_2000_and_2010_from_2000] != [j for i,j in in_2010_and_2000_from_2010]:\n",
    "    # like is seen here, j for j == True\n",
    "    raise Exception(f'FLAWED ASSUMPTION , [j for i,j in 2000] != [j for i,j in 2010]\\n'\n",
    "                    f'len {len(in_2000_and_2010_from_2000)} {len(in_2010_and_2000_from_2010)}')\n",
    "# however i for i == False\n",
    "if of_2000_indexes == of_2010_indexes:\n",
    "    # cheers\n",
    "    raise Exception('FLAWED ASSUMPTION , of_2000_indexes != of_2010_indexes\\n'\n",
    "                    f'len y2k {len(of_2000_indexes)} 2k10 {len(of_2010_indexes)}')  \n",
    "\n",
    "# thin 2000 to shared geo\n",
    "b = b.iloc[of_2000_indexes]\n",
    "# thin 2010 to shared geo\n",
    "o = o.iloc[of_2010_indexes]'''\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
