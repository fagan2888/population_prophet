{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from fbprophet import Prophet\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_by(dataframe,n_clusters=10,converted=False):\n",
    "    '''\n",
    "    inputs:\n",
    "        >> dataframe\n",
    "            > dataframe to be edited\n",
    "        >> n_clusters \n",
    "            > default = 10\n",
    "            > number of clusters for KMeans\n",
    "        >> converted\n",
    "            > default = False\n",
    "            > assumes data is not ready for KMeans \n",
    "                >> if True, assumes df is ready for KMeans\n",
    "    output:\n",
    "        > pd.Dataframe of \n",
    "    '''\n",
    "    # copy data \n",
    "    d = dataframe.copy()  \n",
    "    \n",
    "    '''df conversion'''\n",
    "    # default\n",
    "    if converted!=True:\n",
    "        # copy data for editing\n",
    "        _data_ = d.copy()\n",
    "        \n",
    "        # convert first 3 columns ('Id', 'Id2', 'Geography')\n",
    "        _data = geography_to_zipcode_ids_to_numeric(dataframe=_data_)\n",
    "        \n",
    "        # convert remainder of dataframe\n",
    "        data = to_numeric_but(save_these_columns='none', dataframe=_data)\n",
    "        print(len(data),len(data.columns))\n",
    "\n",
    "    # dataframe has already been converted / otherwise\n",
    "    if converted==True:\n",
    "        data = d  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total population by county (adjusted to 2010 controls)\n",
    "county_2010=pd.read_csv('../../data/NHGIS/nhgis0001_csv/nhgis0001_ts_geog2010_county.csv')\n",
    "# total population by place\n",
    "pop_by_place=pd.read_csv('../../data/NHGIS/nhgis0002_csv/nhgis0002_ts_nominal_place.csv',encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1: (CL8) Total Population\n",
    "#         CL8AA:       Persons: Total\n",
    "#         CL8AAL:      Lower bound: Persons: Total\n",
    "#         CL8AAU:      Upper bound: Persons: Total\n",
    "\n",
    " \n",
    "# Context Fields \n",
    "#         NHGISCODE:   NHGIS Integrated Geographic Unit Code\n",
    "#         GJOIN1970:   GIS Join Match Code, 1970\n",
    "#         GJOIN1980:   GIS Join Match Code, 1980\n",
    "#         GJOIN1990:   GIS Join Match Code, 1990\n",
    "#         GJOIN2000:   GIS Join Match Code, 2000\n",
    "#         GJOIN2010:   GIS Join Match Code, 2010\n",
    "#         GJOIN2012:   GIS Join Match Code, 2012\n",
    "#         STATE:       NHGIS Integrated State Name\n",
    "#         STATEFP:     FIPS State Code\n",
    "#         STATENH:     NHGIS Integrated State Code\n",
    "#         PLACE:       NHGIS Integrated Place Name\n",
    "#         PLACEA:      NHGIS Integrated Place Code\n",
    "#         NAME1970:    Area Name, 1970\n",
    "#         NAME1980:    Area Name, 1980\n",
    "#         NAME1990:    Area Name, 1990\n",
    "#         NAME2000:    Area Name, 2000\n",
    "#         NAME2010:    Area Name, 2010\n",
    "#         NAME2012:    Area Name, 2012\n",
    " \n",
    "# Table 1: (AV0) Total Population\n",
    "#     Time series AA: Persons: Total\n",
    "#         AV0AA1970:   1970: Persons: Total\n",
    "#         AV0AA1980:   1980: Persons: Total\n",
    "#         AV0AA1990:   1990: Persons: Total\n",
    "#         AV0AA2000:   2000: Persons: Total\n",
    "#         AV0AA2010:   2010: Persons: Total\n",
    "#         AV0AA125:    2008-2012: Persons: Total\n",
    "#         AV0AA125M:   Margin of error: 2008-2012: Persons: Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_pop_2010 = pop_by_place.loc[pop_by_place.AV0AA2010.idxmax()]\n",
    "for i in highest_pop_2010[22:24]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***notes***: \n",
    "    - 2010: Persons: Total != 008-2012: Persons: Total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pop_by_place.NHGISCODE),len(pop_by_place.NHGISCODE.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=(len(county_2010.DATAYEAR)/3)-1\n",
    "print(x,x*2,x*3,'\\n',len(county_2010.DATAYEAR),len(county_2010.DATAYEAR.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_2010.iloc[9428]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(county_2010[:3142].STATEA.unique()),county_2010[:3142].STATEA.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=county_2010[:3142].copy()\n",
    "y=county_2010[3143:6286].copy()\n",
    "z=county_2010[6286:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.apply(pd.to_numeric, errors='coerce')\n",
    "x=x.dropna(axis=1, how='all')\n",
    "y=y.apply(pd.to_numeric, errors='coerce')\n",
    "y=y.dropna(axis=1, how='all')\n",
    "z=z.apply(pd.to_numeric, errors='coerce')\n",
    "z=z.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=kmeans_by(dataframe=x,n_clusters=31,converted=True)\n",
    "b=kmeans_by(dataframe=y,n_clusters=31,converted=True)\n",
    "c=kmeans_by(dataframe=z,n_clusters=31,converted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"\n",
    "STEP 0 \n",
    ">> imports; def clean_census & other functions\n",
    "\"\"\"\n",
    "\n",
    "# default cleaning method until proven otherwise\n",
    "def clean_census_frame(csv_path , head=False , reset=True , set_index=False ):\n",
    "    '''\n",
    "    inputs) \n",
    "        >> csv_path\n",
    "            > path to csv\n",
    "        >> head\n",
    "            > default=False\n",
    "                >> if != False\n",
    "                    > integer\n",
    "                        >> returns the first {head} rows (using .head() method) \n",
    "                            > instead of enitre dataframe\n",
    "        >> reset\n",
    "            > default=True\n",
    "                >> resets index after taking out rows\n",
    "            > if set to False\n",
    "                >> will not reset index\n",
    "        >> set_index\n",
    "            > default=False\n",
    "            > if != False\n",
    "                >> will set_index of new df to set_index\n",
    "    output)\n",
    "        >> dataframe cleaned like 2000 Census age&sex by 5-digit Zip Code (also how 2010 for same is cleaned)\n",
    "    how)\n",
    "        1. reads in csv , assumes it's large\n",
    "        2. makes a copy for editing \n",
    "            > and potential future use\n",
    "        3. locates readable column names  and non-readable names \n",
    "            > readable\n",
    "                    > e.g. Estimate; SEX AND AGE - Total population\n",
    "                >> assumes they are currently in row 0\n",
    "            > non-readable\n",
    "                    > e.g. HC01_VC03\n",
    "                >> assumes they are currently == dataframe.columns\n",
    "        4. replaces dataframe.columns (non-readable) with readable column names\n",
    "            > and drops the old 0th column (column where readable names were stored)\n",
    "        \n",
    "    '''\n",
    "    # load data\n",
    "    df = pd.read_csv( csv_path , low_memory=False )\n",
    "\n",
    "    # and copy\n",
    "    _df = df.copy()\n",
    "\n",
    "    # reset column names to current 0th row values\n",
    "    _df.columns = _df.iloc[0]\n",
    "    # new 2000 dataframe without row where values are from\n",
    "    clean_df = _df[1:]\n",
    "    \n",
    "    # default\n",
    "    if reset==True:\n",
    "        # reset index\n",
    "        clean_df = clean_df.reset_index()\n",
    "        \n",
    "    # set_index\n",
    "    if set_index:\n",
    "        clean_df = clean_df.set_index(set_index)\n",
    "    \n",
    "    if head:\n",
    "        # return first {head} rows of dataframe\n",
    "        return clean_df.head(head)\n",
    "    else:\n",
    "        # return dataframe\n",
    "        return clean_df\n",
    "\n",
    "'''\n",
    "STEP 1 \n",
    ">> load data, reset; make copies/**sample\n",
    "'''\n",
    "\n",
    "def load_clean_frames(i=0,n=False):\n",
    "    '''\n",
    "    function) loads data\n",
    "    \n",
    "    input)\n",
    "        >> i\n",
    "            > if 0\n",
    "                >> .reset_index() after deleting row contining column names\n",
    "            > if 1\n",
    "                >> do not .reset_index()\n",
    "        >> head\n",
    "            > default=False (ignore)\n",
    "            > if != False\n",
    "                >> must be int\n",
    "                    > dataframe = dataframe.head(n)\n",
    "    '''\n",
    "    if i==0:\n",
    "        # load with reset\n",
    "        # 2011 \n",
    "        twenty_eleven = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_11_5YR_DP05_with_ann.csv')\n",
    "        # 2012\n",
    "        twenty_twelve = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_12_5YR_DP05_with_ann.csv')\n",
    "        #2013\n",
    "        twenty_thirteen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_13_5YR_DP05_with_ann.csv')\n",
    "        # 2014\n",
    "        twenty_fourteen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_14_5YR_DP05_with_ann.csv')\n",
    "        # 2015\n",
    "        twenty_fifteen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_15_5YR_DP05_with_ann.csv')\n",
    "        #2016\n",
    "        twenty_sixteen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_16_5YR_DP05_with_ann.csv')\n",
    "        #2017\n",
    "        twenty_seventeen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_17_5YR_DP05_with_ann.csv')\n",
    "    if i==1:\n",
    "        # load without reset\n",
    "        # 2011 \n",
    "        twenty_eleven = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_11_5YR_DP05_with_ann.csv',reset=False)\n",
    "        # 2012\n",
    "        twenty_twelve = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_12_5YR_DP05_with_ann.csv',reset=False)\n",
    "        #2013\n",
    "        twenty_thirteen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_13_5YR_DP05_with_ann.csv',reset=False)\n",
    "        # 2014\n",
    "        twenty_fourteen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_14_5YR_DP05_with_ann.csv',reset=False)\n",
    "        # 2015\n",
    "        twenty_fifteen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_15_5YR_DP05_with_ann.csv',reset=False)\n",
    "        #2016\n",
    "        twenty_sixteen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_16_5YR_DP05_with_ann.csv',reset=False)\n",
    "        #2017\n",
    "        twenty_seventeen = clean_census_frame('../../data/American_Community_Survey/aff_download/ACS_17_5YR_DP05_with_ann.csv',reset=False)\n",
    "    \n",
    "    # default\n",
    "    if n==False:\n",
    "        # copy \n",
    "        # 2011 \n",
    "        _y2k11 = twenty_eleven.copy()\n",
    "        # 2012\n",
    "        _y2k12 = twenty_twelve.copy()\n",
    "        #2013\n",
    "        _y2k13 = twenty_thirteen.copy()\n",
    "        # 2014\n",
    "        _y2k14 = twenty_fourteen.copy()\n",
    "        # 2015\n",
    "        _y2k15 = twenty_fifteen.copy()\n",
    "        #2016\n",
    "        _y2k16 = twenty_sixteen.copy()\n",
    "        #2017\n",
    "        _y2k17 = twenty_seventeen.copy()\n",
    "        \n",
    "    # non default, want only first n rows\n",
    "    if n:\n",
    "        # adjust frames to .head(n) \n",
    "        # 2011 \n",
    "        _y2k11 = twenty_eleven.copy().head(n)\n",
    "        # 2012\n",
    "        _y2k12 = twenty_twelve.copy().head(n)\n",
    "        #2013\n",
    "        _y2k13 = twenty_thirteen.copy().head(n)\n",
    "        # 2014\n",
    "        _y2k14 = twenty_fourteen.copy().head(n)\n",
    "        # 2015\n",
    "        _y2k15 = twenty_fifteen.copy().head(n)\n",
    "        #2016\n",
    "        _y2k16 = twenty_sixteen.copy().head(n)\n",
    "        #2017\n",
    "        _y2k17 = twenty_seventeen.copy().head(n)\n",
    "    \n",
    "    # output list of copied frames\n",
    "    return [_y2k11,_y2k12,_y2k13,_y2k14,_y2k15,_y2k16,_y2k17]\n",
    "\n",
    "'''\n",
    "STEP 2 \n",
    ">> identify unique (mostly used in testing); \n",
    ">> convert DataFrame to numeric; convert Geography (Zip Codes) && Ids\n",
    "'''\n",
    "\n",
    "def test_non_unique(column_names):\n",
    "    '''\n",
    "    input) \n",
    "        >> list of column names {column_names}\n",
    "            > columns to check for duplicate instances\n",
    "    output)\n",
    "        >> indexed list of names occouring more than once \n",
    "    '''\n",
    "    # store first instance\n",
    "    first_occour = []\n",
    "    # store 2nd+ instance(s)\n",
    "    non_unique = []\n",
    "    # we're going to want index\n",
    "    for i,_ in enumerate(column_names):\n",
    "        # not first time\n",
    "        if _ not in first_occour:\n",
    "            first_occour.append(_)\n",
    "        # if not first, tag&bag\n",
    "        else:\n",
    "            non_unique.append([i,_])\n",
    "    # output index w/ non-first instances\n",
    "    return non_unique\n",
    "\n",
    "\n",
    "def to_numeric_but(dataframe,save_these_columns='none',e='coerce'):\n",
    "    '''\n",
    "    split into 2 df and rejoin after convert to int\n",
    "    \n",
    "    inputs:\n",
    "        >> save_these_columns=number of columns to save\n",
    "            > currently must include one end of df \n",
    "                >> might could run function multiple times to edit slices\n",
    "                >> single number, not range (yet)\n",
    "                    > if 'none', saves no columns\n",
    "        >> dataframe\n",
    "            > dataframe to shif to numeric (but)\n",
    "        >> e\n",
    "            > for pd.to_numeric, errors=e\n",
    "    output:\n",
    "        >> concatted pd.DataFrame of \n",
    "            > og columns you chose to save\n",
    "            > columns converted to numeric\n",
    "    '''\n",
    "    # copy df for editing\n",
    "    k = dataframe.copy()\n",
    "    \n",
    "    # split\n",
    "    if save_these_columns != 'none':\n",
    "        # columns to save\n",
    "        save_k = k[k.columns[:save_these_columns]]\n",
    "        # columns to edit\n",
    "        switch_k = k[k.columns[save_these_columns:]]\n",
    "    # don't split\n",
    "    else:\n",
    "        # k as is\n",
    "        switch_k = k\n",
    "\n",
    "    # edited columns  # coerce , ignore , raise\n",
    "    swapped_k = switch_k.apply(pd.to_numeric, errors=e)\n",
    "    \n",
    "    # check saving columns\n",
    "    if save_these_columns != 'none':\n",
    "        # new (edited) dataframe (ogsave|swapped)\n",
    "        new_k = pd.concat( [save_k,swapped_k] ,axis=1 )\n",
    "    else:\n",
    "        new_k = swapped_k\n",
    "\n",
    "    return new_k\n",
    "\n",
    "\n",
    "def geography_to_zipcode_ids_to_numeric(dataframe):\n",
    "    '''\n",
    "    convert \n",
    "        >> .Geography values \n",
    "            > like 'ZCTA5 00601' \n",
    "            > to int(00601)\n",
    "        >> .Id values\n",
    "            > like '8600000US00601' \n",
    "            > to int(860000000601)\n",
    "        >> .Id2 values\n",
    "            > like '00601'\n",
    "            > to int(00601)\n",
    "    '''\n",
    "    # copy\n",
    "    df = dataframe.copy()\n",
    "    \n",
    "    # set old Geography\n",
    "    geo = df.Geography\n",
    "    # set old Id\n",
    "    _id = df.Id\n",
    "    # set old Id2\n",
    "    __id2 = df.Id2\n",
    "    \n",
    "    # make new 'Geography' values\n",
    "    new_geos = [int(i[-5:]) for i in geo]\n",
    "    # new 'Id' values\n",
    "    new_id = [int(''.join(i.split('US'))) for i in _id]\n",
    "    # new .Id2 instances\n",
    "    new__id2 = [int(d) for d in __id2]\n",
    "    \n",
    "    # convert dataframe\n",
    "    new_df = df.copy()\n",
    "    new_df.Geography = new_geos\n",
    "    new_df.Id = new_id\n",
    "    new_df.Id2 = new__id2\n",
    "    \n",
    "    # return new df\n",
    "    return new_df\n",
    "\n",
    "'''\n",
    "STEP 3\n",
    ">> run KMeans on dataframe\n",
    "'''\n",
    "\n",
    "def kmeans_by(dataframe,n_clusters=10,converted=False):\n",
    "    '''\n",
    "    inputs:\n",
    "        >> dataframe\n",
    "            > dataframe to be edited\n",
    "        >> n_clusters \n",
    "            > default = 10\n",
    "            > number of clusters for KMeans\n",
    "        >> converted\n",
    "            > default = False\n",
    "            > assumes data is not ready for KMeans \n",
    "                >> if True, assumes df is ready for KMeans\n",
    "    output:\n",
    "        > pd.Dataframe of \n",
    "    '''\n",
    "    # copy data \n",
    "    d = dataframe.copy()  \n",
    "    \n",
    "    '''df conversion'''\n",
    "    # default\n",
    "    if converted!=True:\n",
    "        # copy data for editing\n",
    "        _data_ = d.copy()\n",
    "        \n",
    "        # convert first 3 columns ('Id', 'Id2', 'Geography')\n",
    "        _data = geography_to_zipcode_ids_to_numeric(dataframe=_data_)\n",
    "        \n",
    "        # convert remainder of dataframe\n",
    "        data = to_numeric_but(save_these_columns='none', dataframe=_data)\n",
    "        print(len(data),len(data.columns))\n",
    "\n",
    "    # dataframe has already been converted / otherwise\n",
    "    if converted==True:\n",
    "        data = d\n",
    "    \n",
    "    '''KMeans'''\n",
    "    # fill NaN values\n",
    "    t = data.copy().fillna(0)\n",
    "    \n",
    "    # Convert DataFrame to matrix\n",
    "    mat = t.values\n",
    "    \n",
    "    # Using sklearn\n",
    "    km = KMeans(n_clusters)\n",
    "    # fit our values\n",
    "    km.fit(mat)\n",
    "    \n",
    "    # Get cluster assignment labels\n",
    "    labels = km.labels_\n",
    "    \n",
    "    # Format results as a DataFrame\n",
    "    results = pd.DataFrame([t.index,labels])\n",
    "\n",
    "    # display results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
