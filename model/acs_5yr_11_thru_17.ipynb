{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# default cleaning method until proven otherwise\n",
    "def clean_census_frame(csv_path , head=False , reset=True , set_index=False ):\n",
    "    '''\n",
    "    inputs) \n",
    "        >> csv_path\n",
    "            > path to csv\n",
    "        >> head\n",
    "            > default=False\n",
    "                >> if != False\n",
    "                    > integer\n",
    "                        >> returns the first {head} rows (using .head() method) \n",
    "                            > instead of enitre dataframe\n",
    "        >> reset\n",
    "            > default=True\n",
    "                >> resets index after taking out rows\n",
    "            > if set to False\n",
    "                >> will not reset index\n",
    "        >> set_index\n",
    "            > default=False\n",
    "            > if != False\n",
    "                >> will set_index of new df to set_index\n",
    "    output)\n",
    "        >> dataframe cleaned like 2000 Census age&sex by 5-digit Zip Code (also how 2010 for same is cleaned)\n",
    "    how)\n",
    "        1. reads in csv , assumes it's large\n",
    "        2. makes a copy for editing \n",
    "            > and potential future use\n",
    "        3. locates readable column names  and non-readable names \n",
    "            > readable\n",
    "                    > e.g. Estimate; SEX AND AGE - Total population\n",
    "                >> assumes they are currently in row 0\n",
    "            > non-readable\n",
    "                    > e.g. HC01_VC03\n",
    "                >> assumes they are currently == dataframe.columns\n",
    "        4. replaces dataframe.columns (non-readable) with readable column names\n",
    "            > and drops the old 0th column (column where readable names were stored)\n",
    "        \n",
    "    '''\n",
    "    # load data\n",
    "    df = pd.read_csv( csv_path , low_memory=False )\n",
    "\n",
    "    # and copy\n",
    "    _df = df.copy()\n",
    "\n",
    "    # reset column names to current 0th row values\n",
    "    _df.columns = _df.iloc[0]\n",
    "    # new 2000 dataframe without row where values are from\n",
    "    clean_df = _df[1:]\n",
    "    \n",
    "    # default\n",
    "    if reset==True:\n",
    "        # reset index\n",
    "        clean_df = clean_df.reset_index()\n",
    "        \n",
    "    # set_index\n",
    "    if set_index:\n",
    "        clean_df = clean_df.set_index(set_index)\n",
    "    \n",
    "    if head:\n",
    "        # return first {head} rows of dataframe\n",
    "        return clean_df.head(head)\n",
    "    else:\n",
    "        # return dataframe\n",
    "        return clean_df\n",
    "    \n",
    "def bring_the_5yr_acs_2k11_thru_2k17():\n",
    "    '''\n",
    "    inputs)\n",
    "        >> list_of_paths\n",
    "            > paths to each raw dataframe\n",
    "    output)\n",
    "        >> list of modified dataframes\n",
    "    function)\n",
    "        1. load and copy data\n",
    "        2. \n",
    "    '''\n",
    "    # load 2011 \n",
    "    y2k11 = clean_census_frame('../data/acs/aff_download/ACS_11_5YR_DP05_with_ann.csv',reset=False)\n",
    "    # copy\n",
    "    y11 = y2k11.copy()\n",
    "    # 2012\n",
    "    y2k12 = clean_census_frame('../data/acs/aff_download/ACS_12_5YR_DP05_with_ann.csv',reset=False)\n",
    "    y12 = y2k12.copy()\n",
    "    #2013\n",
    "    y2k13 = clean_census_frame('../data/acs/aff_download/ACS_13_5YR_DP05_with_ann.csv',reset=False)\n",
    "    y13 = y2k13.copy()\n",
    "    # 2014\n",
    "    y2k14 = clean_census_frame('../data/acs/aff_download/ACS_14_5YR_DP05_with_ann.csv',reset=False)\n",
    "    y14 = y2k14.copy()\n",
    "    # 2015\n",
    "    y2k15 = clean_census_frame('../data/acs/aff_download/ACS_15_5YR_DP05_with_ann.csv',reset=False)\n",
    "    y15 = y2k15.copy()\n",
    "    #2016\n",
    "    y2k16 = clean_census_frame('../data/acs/aff_download/ACS_16_5YR_DP05_with_ann.csv',reset=False)\n",
    "    y16 = y2k16.copy()\n",
    "    #2017\n",
    "    y2k17 = clean_census_frame('../data/acs/aff_download/ACS_17_5YR_DP05_with_ann.csv',reset=False)\n",
    "    y17 = y2k17.copy()\n",
    "\n",
    "    '''copy data for editing and extracting info'''\n",
    "    # 2011\n",
    "    # 2012\n",
    "    # 2013\n",
    "    # 2014\n",
    "    # 2015\n",
    "    # 2016\n",
    "    # 2017\n",
    "\n",
    "    '''identify columns'''\n",
    "    # 2011\n",
    "    tags11 = y11.columns  \n",
    "    # 2012\n",
    "    tags12 = y12.columns  \n",
    "    #2013\n",
    "    tags13 = y13.columns  \n",
    "    # 2014\n",
    "    tags14 = y14.columns  \n",
    "    # 2015\n",
    "    tags15 = y15.columns  \n",
    "    #2016\n",
    "    tags16 = y16.columns  \n",
    "    # 2017\n",
    "    tags17 = y17.columns \n",
    "\n",
    "    '''identify common columns'''\n",
    "    # collection of columns appearing in all 7 dataframes 2011-2017\n",
    "    common_tags = [tag for tag in tags17 if tag in tags11 & tags12 & tags13 & tags14 & tags15 & tags16]\n",
    "\n",
    "    '''identify non common columns for specific frames'''\n",
    "    # 2011\n",
    "    uncommon_11 = [tag for tag in y11.columns if tag not in common_tags]\n",
    "    # 2012\n",
    "    uncommon_12 = [tag for tag in y12.columns if tag not in common_tags]\n",
    "    # 2013\n",
    "    uncommon_13 = [tag for tag in y13.columns if tag not in common_tags]\n",
    "    # 2014\n",
    "    uncommon_14 = [tag for tag in y14.columns if tag not in common_tags]\n",
    "    # 2015\n",
    "    uncommon_15 = [tag for tag in y15.columns if tag not in common_tags]\n",
    "    # 2016\n",
    "    uncommon_16 = [tag for tag in y16.columns if tag not in common_tags]\n",
    "    # 2017\n",
    "    uncommon_17 = [tag for tag in y17.columns if tag not in common_tags]\n",
    "\n",
    "    \"\"\"drop each frame's uncommon columns, reset index\"\"\"\n",
    "    # 2011\n",
    "    y11 = y11.drop(uncommon_11,axis=1).reset_index()\n",
    "    # # 2012\n",
    "    y12 = y12.drop(uncommon_12,axis=1).reset_index()\n",
    "    # # 2013\n",
    "    y13 = y13.drop(uncommon_13,axis=1).reset_index()\n",
    "    # # 2014\n",
    "    y14 = y14.drop(uncommon_14,axis=1).reset_index()\n",
    "    # # 2015\n",
    "    y15 = y15.drop(uncommon_15,axis=1).reset_index()\n",
    "    # # 2016\n",
    "    y16 = y16.drop(uncommon_16,axis=1).reset_index()\n",
    "    # # 2017\n",
    "    y17 = y17.drop(uncommon_17,axis=1).reset_index()\n",
    "    \n",
    "    return [y11,y12,y13,y14,y15,y16,y17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = bring_the_5yr_acs_2k11_thru_2k17()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_000 = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33120 rows x 220 columns\n",
      "33120 rows x 220 columns\n",
      "33120 rows x 212 columns\n",
      "33120 rows x 212 columns\n",
      "33120 rows x 212 columns\n",
      "33120 rows x 212 columns\n",
      "33120 rows x 212 columns\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_000)):\n",
    "    print(f'{len(test_000[i])} rows x {len(test_000[i].iloc[1])} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretty ok to assume\n",
      "2011-2012 are identical and 2013-2017 are identical\n",
      "but 2011-2012 and 2013-2017 are different\n"
     ]
    }
   ],
   "source": [
    "# number of identical columns 2011 and 2012 is same number as all columns in 2011\n",
    "# and count of columns in 2012 is same as count in 2011\n",
    "if sum(test_000[0].columns == test_000[1].columns) == len(test_000[0].columns) and len(test_000[1].columns) == len(test_000[0].columns):\n",
    "    # number of columns for 2013 is same as number that are same between 2013 and 2014 and between 2014 and 2015 \n",
    "    if len(test_000[2].columns) == sum(test_000[2].columns == test_000[3].columns) & sum(test_000[3].columns == test_000[4].columns):\n",
    "        # number of columns for 2017 is same as number that are same between 2016 and 2014 and between 2017 and 2015 \n",
    "        if len(test_000[6].columns) == sum(test_000[5].columns == test_000[3].columns) & sum(test_000[6].columns == test_000[4].columns):\n",
    "            if len(test_000[0].columns) != len(test_000[5].columns) and len(test_000[5].columns) == len(test_000[5].columns):\n",
    "                print('pretty ok to assume\\n2011-2012 are identical and 2013-2017 are identical\\nbut 2011-2012 and 2013-2017 are different')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2k11 = test_000[0]\n",
    "_2k15 = test_000[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 212)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_2k11.columns), len(_2k15.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204, 204)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(_2k11.columns)), len(set(_2k15.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate; SEX AND AGE - 18 years and over\n",
      "Margin of Error; SEX AND AGE - 18 years and over\n",
      "Percent; SEX AND AGE - 18 years and over\n",
      "Percent Margin of Error; SEX AND AGE - 18 years and over\n",
      "Estimate; SEX AND AGE - 65 years and over\n",
      "Margin of Error; SEX AND AGE - 65 years and over\n",
      "Percent; SEX AND AGE - 65 years and over\n",
      "Percent Margin of Error; SEX AND AGE - 65 years and over\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_15 = []\n",
    "repeat_15=0\n",
    "for i in _2k15.columns:\n",
    "    if i not in out_15:\n",
    "        out_15.append(i)\n",
    "    else:\n",
    "        print(i)\n",
    "        repeat_15+=1\n",
    "repeat_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate; SEX AND AGE - 18 years and over\n",
      "Margin of Error; SEX AND AGE - 18 years and over\n",
      "Percent; SEX AND AGE - 18 years and over\n",
      "Percent Margin of Error; SEX AND AGE - 18 years and over\n",
      "Estimate; SEX AND AGE - 65 years and over\n",
      "Margin of Error; SEX AND AGE - 65 years and over\n",
      "Percent; SEX AND AGE - 65 years and over\n",
      "Percent Margin of Error; SEX AND AGE - 65 years and over\n",
      "Estimate; RACE - One race\n",
      "Margin of Error; RACE - One race\n",
      "Percent; RACE - One race\n",
      "Percent Margin of Error; RACE - One race\n",
      "Estimate; RACE - Two or more races\n",
      "Margin of Error; RACE - Two or more races\n",
      "Percent; RACE - Two or more races\n",
      "Percent Margin of Error; RACE - Two or more races\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_11 = []\n",
    "repeat_11 = 0\n",
    "for i in _2k11.columns:\n",
    "    if i not in out_11:\n",
    "        out_11.append(i)\n",
    "    else:\n",
    "        print(i)\n",
    "        repeat_11+=1        \n",
    "repeat_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
